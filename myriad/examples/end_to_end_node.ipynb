{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Use this notebook to run the Neural ODE-based end-to-end imitation learning algorithm, learning a black-box model of the dynamics.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, we load the Neural ODE end-to-end imitation learning algorithm."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the necessary libraries\n",
    "from myriad.config import HParams, Config, SystemType\n",
    "from myriad.experiments.node_e2e_sysid import run_node_endtoend"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next we choose which hyperparameters to use, as in previous settings. We choose a smaller size for the neural network for better stability and faster training; larger networks can also be used."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create hyperparameter and config objects\n",
    "# This is the place to specify environment or solver hyperparameters; see config.py for a full list.\n",
    "hp = HParams(system=SystemType.CANCERTREATMENT,\n",
    "             intervals=1,\n",
    "             controls_per_interval=100,\n",
    "             hidden_layers=(50, 50))\n",
    "cfg = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that since we are learning a black-box (implicit) dynamics model, there is no simple way to interpret the learned parameters as we do in the parametric model case."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Look for losses in the `losses` directory, and for the current neural network parameters in the `params` directory. Look in the `intermediate_guesses` directory for intermediate guesses at the best control trajectory. Finally, various plots will be generated and put in the `plots` directory, so you can see how the learning process went.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run_node_endtoend(hp, cfg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}